{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports and definitions\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense, BatchNormalization, Activation\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  #To address OSError: image file is truncated \n",
    "\n",
    "# Testing Xception implementation.\n",
    "from keras.applications import xception\n",
    "\n",
    "# Paths to images \n",
    "training_path = 'dogImages/train'\n",
    "validation_path = 'dogImages/valid'\n",
    "test_path = 'dogImages/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to use transfer learning for this. The following steps create the bottleneck features for the Xception CNN with data augmentation. \n",
    "\n",
    "generate_bottelneck_features_n_labels(generator, batch_size, model): Takes in the data generator and model, and it returns the bottleneck_features and the corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Keras doesn't seem to give an option to get labels with predict_generator, doing it manually. \n",
    "def generate_bottelneck_features_n_labels(generator, batch_size, model):\n",
    "    ind = 0\n",
    "    list_batches = []\n",
    "    list_labels = []\n",
    "    for images, label in generator:\n",
    "        bott_features = model.predict(images)\n",
    "        list_batches.append(bott_features)\n",
    "        list_labels.append(label)\n",
    "        if generator.samples//batch_size+1 <= ind:\n",
    "            break\n",
    "        ind += 1\n",
    "    bottleneck_features = np.vstack(list_batches)\n",
    "    labels = np.vstack(list_labels)\n",
    "    return bottleneck_features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6680 images belonging to 133 classes.\n",
      "Found 835 images belonging to 133 classes.\n",
      "Found 836 images belonging to 133 classes.\n"
     ]
    }
   ],
   "source": [
    "if (not os.path.isfile('bottleneck_features/bf_data_aug_xception_train.npz')) \\\n",
    "    or (not os.path.isfile('bottleneck_features/bf_data_aug_xception_validation.npz')) \\\n",
    "    or (not os.path.isfile('bottleneck_features/bf_data_aug_xception_test.npz')):\n",
    "    \n",
    "    \n",
    "    batch_size = 32\n",
    "    # Instanciate the Xception model. Don't include the FC layers.\n",
    "    xception_model = xception.Xception(include_top=False, weights='imagenet')\n",
    "\n",
    "    # Data augmentation on the training data.\n",
    "    data_generator_train = ImageDataGenerator(\n",
    "                                        rescale=1./255,\n",
    "                                        zoom_range=0.2,\n",
    "                                        rotation_range=10,\n",
    "                                        width_shift_range=0.1,\n",
    "                                        height_shift_range=0.1,\n",
    "                                        horizontal_flip=True)\n",
    "\n",
    "    # data generator for validation & test data.\n",
    "    data_generator_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = data_generator_train.flow_from_directory(training_path, \n",
    "                                                        target_size=(224, 224), \n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        shuffle=False)\n",
    "\n",
    "    validation_generator = data_generator_test.flow_from_directory(validation_path, \n",
    "                                                        target_size=(224, 224), \n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        shuffle=False)\n",
    "\n",
    "    test_generator = data_generator_test.flow_from_directory(test_path, \n",
    "                                                        target_size=(224, 224), \n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        shuffle=False)\n",
    "    \n",
    "    \n",
    "    train_xception, labels_train_exception = generate_bottelneck_features_n_labels(train_generator, batch_size, xception_model)\n",
    "    valid_xception, labels_valid_exception = generate_bottelneck_features_n_labels(validation_generator, batch_size, xception_model)\n",
    "    test_xception, labels_test_exception = generate_bottelneck_features_n_labels(test_generator, batch_size, xception_model)\n",
    "    \n",
    "    np.savez(open('bottleneck_features/bf_data_aug_xception_train.npz', 'wb'), train_xception=train_xception, labels_train_exception=labels_train_exception)\n",
    "    np.savez(open('bottleneck_features/bf_data_aug_xception_validation.npz', 'wb'), valid_xception=valid_xception, labels_valid_exception=labels_valid_exception)\n",
    "    np.savez(open('bottleneck_features/bf_data_aug_xception_test.npz', 'wb'), test_xception=test_xception, labels_test_exception=labels_test_exception)\n",
    "    \n",
    "else:\n",
    "    train_data_xception = np.load('bottleneck_features/bf_data_aug_xception_train.npz')\n",
    "    train_xception = train_data_xception['train_xception']\n",
    "    labels_train_exception = train_data_xception['labels_train_exception']\n",
    "    \n",
    "    valid_data_xception = np.load('bottleneck_features/bf_data_aug_xception_validation.npz')\n",
    "    valid_xception = valid_data_xception['valid_xception']\n",
    "    labels_valid_exception = valid_data_xception['labels_valid_exception']\n",
    "    \n",
    "    test_data_xception = np.load('bottleneck_features/bf_data_aug_xception_test.npz')\n",
    "    test_xception = test_data_xception['test_xception']\n",
    "    labels_test_exception = test_data_xception['labels_test_exception']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the bottleneck features, create the NN for the FC layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 133)               272517    \n",
      "=================================================================\n",
      "Total params: 272,517.0\n",
      "Trainable params: 272,517.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model = Sequential()\n",
    "my_model.add(GlobalAveragePooling2D(input_shape=train_xception.shape[1:]))\n",
    "# my_model.add(Dense(1000, activation='relu'))\n",
    "# my_model.add(BatchNormalization())\n",
    "# my_model.add(Dropout(0.2))\n",
    "# my_model.add(Dense(500, activation='relu'))\n",
    "# my_model.add(BatchNormalization())\n",
    "my_model.add(Dropout(0.3))\n",
    "my_model.add(Dense(133, activation='softmax'))\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define optimizer, loss function and metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr=0.002)\n",
    "my_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6712 samples, validate on 867 samples\n",
      "Epoch 1/10\n",
      "6624/6712 [============================>.] - ETA: 0s - loss: 1.2706 - acc: 0.6727Epoch 00000: val_loss improved from inf to 0.56355, saving model to saved_models/weights.best.xception_transfer.hdf5\n",
      "6712/6712 [==============================] - 3s - loss: 1.2620 - acc: 0.6742 - val_loss: 0.5636 - val_acc: 0.8235\n",
      "Epoch 2/10\n",
      "6688/6712 [============================>.] - ETA: 0s - loss: 0.4462 - acc: 0.8580Epoch 00001: val_loss improved from 0.56355 to 0.52565, saving model to saved_models/weights.best.xception_transfer.hdf5\n",
      "6712/6712 [==============================] - 2s - loss: 0.4459 - acc: 0.8580 - val_loss: 0.5256 - val_acc: 0.8316\n",
      "Epoch 3/10\n",
      "6624/6712 [============================>.] - ETA: 0s - loss: 0.2853 - acc: 0.9115Epoch 00002: val_loss improved from 0.52565 to 0.49889, saving model to saved_models/weights.best.xception_transfer.hdf5\n",
      "6712/6712 [==============================] - 2s - loss: 0.2857 - acc: 0.9115 - val_loss: 0.4989 - val_acc: 0.8362\n",
      "Epoch 4/10\n",
      "6688/6712 [============================>.] - ETA: 0s - loss: 0.2095 - acc: 0.9347Epoch 00003: val_loss did not improve\n",
      "6712/6712 [==============================] - 2s - loss: 0.2089 - acc: 0.9349 - val_loss: 0.5163 - val_acc: 0.8362\n",
      "Epoch 5/10\n",
      "6656/6712 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9569Epoch 00004: val_loss improved from 0.49889 to 0.48469, saving model to saved_models/weights.best.xception_transfer.hdf5\n",
      "6712/6712 [==============================] - 2s - loss: 0.1513 - acc: 0.9569 - val_loss: 0.4847 - val_acc: 0.8501\n",
      "Epoch 6/10\n",
      "6624/6712 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9672Epoch 00005: val_loss did not improve\n",
      "6712/6712 [==============================] - 2s - loss: 0.1198 - acc: 0.9669 - val_loss: 0.4924 - val_acc: 0.8431\n",
      "Epoch 7/10\n",
      "6592/6712 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9771Epoch 00006: val_loss improved from 0.48469 to 0.47554, saving model to saved_models/weights.best.xception_transfer.hdf5\n",
      "6712/6712 [==============================] - 3s - loss: 0.0925 - acc: 0.9768 - val_loss: 0.4755 - val_acc: 0.8420\n",
      "Epoch 8/10\n",
      "6656/6712 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9811Epoch 00007: val_loss did not improve\n",
      "6712/6712 [==============================] - 2s - loss: 0.0796 - acc: 0.9811 - val_loss: 0.4864 - val_acc: 0.8512\n",
      "Epoch 9/10\n",
      "6688/6712 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9836Epoch 00008: val_loss did not improve\n",
      "6712/6712 [==============================] - 2s - loss: 0.0665 - acc: 0.9835 - val_loss: 0.5029 - val_acc: 0.8397\n",
      "Epoch 10/10\n",
      "6656/6712 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9838Epoch 00009: val_loss did not improve\n",
      "6712/6712 [==============================] - 2s - loss: 0.0658 - acc: 0.9838 - val_loss: 0.5179 - val_acc: 0.8454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5705bc80f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.xception_transfer.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "my_model.fit(train_xception, labels_train_exception, \n",
    "          validation_data=(valid_xception, labels_valid_exception),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best weights for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.load_weights('saved_models/weights.best.xception_transfer.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy over test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 83.8710%\n"
     ]
    }
   ],
   "source": [
    "# Expanding dimensions for the input features, adding 1 for the num of samples. \n",
    "# So it matches with the expected input from Keras\n",
    "# Using argmax to retrieve the index of the dog breed with maximum probability.\n",
    "Xception_predictions = [np.argmax(my_model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_xception]\n",
    "\n",
    "# report test accuracy\n",
    "# Checking indexes from predictions and test labels.\n",
    "test_accuracy = 100*np.sum(np.array(Xception_predictions)==np.argmax(labels_test_exception, axis=1))/len(Xception_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "83% Accuracy with transfer learning but no fine tunning. \n",
    "Fine tunning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_15 (InputLayer)            (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)            (None, None, None, 32 864                                          \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormalizat (None, None, None, 32 128                                          \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)    (None, None, None, 32 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)            (None, None, None, 64 18432                                        \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormalizat (None, None, None, 64 256                                          \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)    (None, None, None, 64 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2D (None, None, None, 12 8768                                         \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormali (None, None, None, 12 512                                          \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation) (None, None, None, 12 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2D (None, None, None, 12 17536                                        \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormali (None, None, None, 12 512                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)               (None, None, None, 12 8192                                         \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, None, None, 12 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNor (None, None, None, 12 512                                          \n",
      "____________________________________________________________________________________________________\n",
      "add_169 (Add)                    (None, None, None, 12 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation) (None, None, None, 12 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2D (None, None, None, 25 33920                                        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormali (None, None, None, 25 1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation) (None, None, None, 25 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2D (None, None, None, 25 67840                                        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormali (None, None, None, 25 1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)               (None, None, None, 25 32768                                        \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, None, None, 25 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNor (None, None, None, 25 1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "add_170 (Add)                    (None, None, None, 25 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation) (None, None, None, 25 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2D (None, None, None, 72 188672                                       \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)               (None, None, None, 72 186368                                       \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNor (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "add_171 (Add)                    (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "add_172 (Add)                    (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "add_173 (Add)                    (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "add_174 (Add)                    (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "add_175 (Add)                    (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation) (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2D (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormali (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "add_176 (Add)                    (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activation (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv2 (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNormal (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activation (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv2 (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNormal (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activation (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv2 (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNormal (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "add_177 (Add)                    (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activation (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv2 (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNormal (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activation (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv2 (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNormal (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activation (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv2 (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNormal (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "add_178 (Add)                    (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activation (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv2 (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNormal (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activation (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv2 (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNormal (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activation (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv2 (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNormal (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "add_179 (Add)                    (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activation (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv2 (None, None, None, 72 536536                                       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNormal (None, None, None, 72 2912                                         \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activation (None, None, None, 72 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv2 (None, None, None, 10 752024                                       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNormal (None, None, None, 10 4096                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)               (None, None, None, 10 745472                                       \n",
      "____________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)      (None, None, None, 10 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNor (None, None, None, 10 4096                                         \n",
      "____________________________________________________________________________________________________\n",
      "add_180 (Add)                    (None, None, None, 10 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv2 (None, None, None, 15 1582080                                      \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNormal (None, None, None, 15 6144                                         \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activation (None, None, None, 15 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv2 (None, None, None, 20 3159552                                      \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNormal (None, None, None, 20 8192                                         \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activation (None, None, None, 20 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_15 (Glo (None, 2048)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 2048)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 133)           272517                                       \n",
      "====================================================================================================\n",
      "Total params: 21,133,997.0\n",
      "Trainable params: 7,060,901.0\n",
      "Non-trainable params: 14,073,096.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "xception_model = xception.Xception(include_top=False, weights='imagenet')\n",
    "# Taking the output on the Conv layers.\n",
    "bottleneck_output = xception_model.output\n",
    "fc_layers = GlobalAveragePooling2D()(bottleneck_output)\n",
    "fc_layers = Dropout(0.3)(fc_layers)\n",
    "y_hat = Dense(133, activation='softmax')(fc_layers)\n",
    "transfer_model = Model(inputs=xception_model.input, outputs=y_hat)\n",
    "\n",
    "# Finetunning the last two big convolutional blocks Blocks12/13\n",
    "for layer in transfer_model.layers[:-19]:\n",
    "    layer.trainable = False\n",
    "\n",
    "transfer_model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr=0.002)\n",
    "transfer_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6680 images belonging to 133 classes.\n",
      "Found 835 images belonging to 133 classes.\n",
      "Epoch 1/10\n",
      "207/208 [============================>.] - ETA: 0s - loss: 1.4223 - acc: 0.5974Epoch 00000: val_loss improved from inf to 1.41222, saving model to saved_models/weights.best.xception_transfer.finetunning.hdf5\n",
      "208/208 [==============================] - 149s - loss: 1.4207 - acc: 0.5980 - val_loss: 1.4122 - val_acc: 0.6490\n",
      "Epoch 2/10\n",
      "207/208 [============================>.] - ETA: 0s - loss: 0.9712 - acc: 0.7062Epoch 00001: val_loss did not improve\n",
      "208/208 [==============================] - 118s - loss: 0.9751 - acc: 0.7051 - val_loss: 1.5195 - val_acc: 0.6451\n",
      "Epoch 3/10\n",
      "207/208 [============================>.] - ETA: 0s - loss: 0.7728 - acc: 0.7587Epoch 00002: val_loss improved from 1.41222 to 1.24515, saving model to saved_models/weights.best.xception_transfer.finetunning.hdf5\n",
      "208/208 [==============================] - 119s - loss: 0.7732 - acc: 0.7587 - val_loss: 1.2452 - val_acc: 0.6961\n",
      "Epoch 4/10\n",
      "207/208 [============================>.] - ETA: 0s - loss: 0.6311 - acc: 0.8032Epoch 00003: val_loss did not improve\n",
      "208/208 [==============================] - 118s - loss: 0.6316 - acc: 0.8028 - val_loss: 1.2992 - val_acc: 0.6743\n",
      "Epoch 5/10\n",
      "207/208 [============================>.] - ETA: 0s - loss: 0.5542 - acc: 0.8265Epoch 00004: val_loss did not improve\n",
      "208/208 [==============================] - 118s - loss: 0.5549 - acc: 0.8263 - val_loss: 1.2899 - val_acc: 0.7024\n",
      "Epoch 6/10\n",
      "207/208 [============================>.] - ETA: 0s - loss: 0.4836 - acc: 0.8472Epoch 00005: val_loss did not improve\n",
      "208/208 [==============================] - 118s - loss: 0.4845 - acc: 0.8470 - val_loss: 1.2856 - val_acc: 0.7011\n",
      "Epoch 7/10\n",
      "207/208 [============================>.] - ETA: 0s - loss: 0.4271 - acc: 0.8614Epoch 00006: val_loss did not improve\n",
      "208/208 [==============================] - 118s - loss: 0.4265 - acc: 0.8618 - val_loss: 1.2550 - val_acc: 0.7139\n",
      "Epoch 8/10\n",
      "207/208 [============================>.] - ETA: 0s - loss: 0.4058 - acc: 0.8696Epoch 00007: val_loss improved from 1.24515 to 1.12804, saving model to saved_models/weights.best.xception_transfer.finetunning.hdf5\n",
      "208/208 [==============================] - 119s - loss: 0.4053 - acc: 0.8696 - val_loss: 1.1280 - val_acc: 0.7223\n",
      "Epoch 9/10\n",
      "207/208 [============================>.] - ETA: 0s - loss: 0.3349 - acc: 0.8897Epoch 00008: val_loss did not improve\n",
      "208/208 [==============================] - 118s - loss: 0.3347 - acc: 0.8900 - val_loss: 1.1908 - val_acc: 0.6999\n",
      "Epoch 10/10\n",
      "207/208 [============================>.] - ETA: 0s - loss: 0.3068 - acc: 0.9002Epoch 00009: val_loss did not improve\n",
      "208/208 [==============================] - 119s - loss: 0.3059 - acc: 0.9005 - val_loss: 1.3827 - val_acc: 0.7139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efdb25d8e80>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.xception_transfer.finetunning.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# Data augmentation on the training data.\n",
    "data_generator_train = ImageDataGenerator(\n",
    "                                    rescale=1./255,\n",
    "                                    zoom_range=0.2,\n",
    "                                    rotation_range=10,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    horizontal_flip=True)\n",
    "\n",
    "# data generator for validation & test data.\n",
    "data_generator_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = data_generator_train.flow_from_directory(training_path, \n",
    "                                                    target_size=(224, 224), \n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "validation_generator = data_generator_test.flow_from_directory(validation_path, \n",
    "                                                    target_size=(224, 224), \n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "transfer_model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples//batch_size, \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=validation_generator.samples//batch_size,\n",
    "                    epochs=epochs, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c7db99339fca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# So it matches with the expected input from Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Using argmax to retrieve the index of the dog breed with maximum probability.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mXception_finetune_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransfer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# report test accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_generator' is not defined"
     ]
    }
   ],
   "source": [
    "my_model.load_weights('saved_models/weights.best.xception_transfer.finetunning.hdf5')\n",
    "# Expanding dimensions for the input features, adding 1 for the num of samples. \n",
    "# So it matches with the expected input from Keras\n",
    "# Using argmax to retrieve the index of the dog breed with maximum probability.\n",
    "\n",
    "\n",
    "Xception_finetune_predictions = [np.argmax(transfer_model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_generator]\n",
    "\n",
    "# report test accuracy\n",
    "# Checking indexes from predictions and test labels.\n",
    "test_accuracy = 100*np.sum(np.array(Xception_finetune_predictions)==np.argmax(labels_test_exception, axis=1))/len(Xception_finetune_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
