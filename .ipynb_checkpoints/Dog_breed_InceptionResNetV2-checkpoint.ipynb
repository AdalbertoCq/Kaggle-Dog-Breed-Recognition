{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and definitions\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense, BatchNormalization, Activation\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  #To address OSError: image file is truncated \n",
    "\n",
    "# Testing Xception implementation.\n",
    "from keras.applications import inception_resnet_v2\n",
    "\n",
    "# Paths to images \n",
    "training_path = '/Users/aclaudioquiros/Documents/ML Data/Data/Dog Breed Project/dogImages/train'\n",
    "validation_path = '/Users/aclaudioquiros/Documents/ML Data/Data/Dog Breed Project/dogImages/valid'\n",
    "test_path = '/Users/aclaudioquiros/Documents/ML Data/Data/Dog Breed Project/dogImages/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to use transfer learning for this. The following steps create the bottleneck features for the Xception CNN with data augmentation. \n",
    "\n",
    "generate_bottelneck_features_n_labels(generator, batch_size, model): Takes in the data generator and model, and it returns the bottleneck_features and the corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since Keras doesn't seem to give an option to get labels with predict_generator, doing it manually. \n",
    "def generate_bottelneck_features_n_labels(generator, batch_size, model):\n",
    "    ind = 0\n",
    "    list_batches = []\n",
    "    list_labels = []\n",
    "    for images, label in generator:\n",
    "        bott_features = model.predict(images)\n",
    "        list_batches.append(bott_features)\n",
    "        list_labels.append(label)\n",
    "        if generator.samples//batch_size+1 <= ind:\n",
    "            break\n",
    "        ind += 1\n",
    "    bottleneck_features = np.vstack(list_batches)\n",
    "    labels = np.vstack(list_labels)\n",
    "    return bottleneck_features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 21s 0us/step\n",
      "Found 6680 images belonging to 133 classes.\n",
      "Found 835 images belonging to 133 classes.\n",
      "Found 836 images belonging to 133 classes.\n"
     ]
    }
   ],
   "source": [
    "if (not os.path.isfile('bottleneck_features/bf_data_aug_inception_resnet_v2_train.npz')) \\\n",
    "    or (not os.path.isfile('bottleneck_features/bf_data_aug_inception_resnet_v2_validation.npz')) \\\n",
    "    or (not os.path.isfile('bottleneck_features/bf_data_aug_inception_resnet_v2_test.npz')):\n",
    "    \n",
    "    \n",
    "    batch_size = 32\n",
    "    # Instanciate the inception model. Don't include the FC layers.\n",
    "    inception_model = inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet')\n",
    "\n",
    "    # Data augmentation on the training data.\n",
    "    data_generator_train = ImageDataGenerator(\n",
    "                                        rescale=1./255,\n",
    "                                        zoom_range=0.2,\n",
    "                                        rotation_range=10,\n",
    "                                        width_shift_range=0.1,\n",
    "                                        height_shift_range=0.1,\n",
    "                                        horizontal_flip=True)\n",
    "\n",
    "    # data generator for validation & test data.\n",
    "    data_generator_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = data_generator_train.flow_from_directory(training_path, \n",
    "                                                        target_size=(224, 224), \n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        shuffle=False)\n",
    "\n",
    "    validation_generator = data_generator_test.flow_from_directory(validation_path, \n",
    "                                                        target_size=(224, 224), \n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        shuffle=False)\n",
    "\n",
    "    test_generator = data_generator_test.flow_from_directory(test_path, \n",
    "                                                        target_size=(224, 224), \n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        shuffle=False)\n",
    "    \n",
    "    \n",
    "    train_inception_resnet_v2, labels_train_inception_resnet_v2 = generate_bottelneck_features_n_labels(train_generator, batch_size, inception_model)\n",
    "    valid_inception_resnet_v2, labels_valid_inception_resnet_v2 = generate_bottelneck_features_n_labels(validation_generator, batch_size, inception_model)\n",
    "    test_inception_resnet_v2, labels_test_inception_resnet_v2 = generate_bottelneck_features_n_labels(test_generator, batch_size, inception_model)\n",
    "    \n",
    "    np.savez(open('bottleneck_features/bf_data_aug_inception_resnet_v2_train.npz', 'wb'), train_inception_resnet_v2=train_inception_resnet_v2, labels_train_inception_resnet_v2=labels_train_inception_resnet_v2)\n",
    "    np.savez(open('bottleneck_features/bf_data_aug_inception_resnet_v2_validation.npz', 'wb'), valid_inception_resnet_v2=valid_inception_resnet_v2, labels_valid_inception_resnet_v2=labels_valid_inception_resnet_v2)\n",
    "    np.savez(open('bottleneck_features/bf_data_aug_inception_resnet_v2_test.npz', 'wb'), test_inception_resnet_v2=test_inception_resnet_v2, labels_test_inception_resnet_v2=labels_test_inception_resnet_v2)\n",
    "    \n",
    "else:\n",
    "    train_data_inception_resnet_v2 = np.load('bottleneck_features/bf_data_aug_inception_resnet_v2_train.npz')\n",
    "    train_inception_resnet_v2 = train_data_inception_resnet_v2['train_inception_resnet_v2']\n",
    "    labels_train_inception_resnet_v2 = train_data_inception_resnet_v2['labels_train_inception_resnet_v2']\n",
    "    \n",
    "    valid_data_inception_resnet_v2 = np.load('bottleneck_features/bf_data_aug_inception_resnet_v2_validation.npz')\n",
    "    valid_inception_resnet_v2 = valid_data_inception_resnet_v2['valid_inception_resnet_v2']\n",
    "    labels_valid_inception_resnet_v2 = valid_data_inception_resnet_v2['labels_valid_inception_resnet_v2']\n",
    "    \n",
    "    test_data_inception_resnet_v2 = np.load('bottleneck_features/bf_data_aug_inception_resnet_v2_test.npz')\n",
    "    test_inception_resnet_v2 = test_data_inception_resnet_v2['test_inception_resnet_v2']\n",
    "    labels_test_inception_resnet_v2 = test_data_inception_resnet_v2['labels_test_inception_resnet_v2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the bottleneck features, create the NN for the FC layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_4 ( (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 133)               204421    \n",
      "=================================================================\n",
      "Total params: 204,421\n",
      "Trainable params: 204,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model = Sequential()\n",
    "my_model.add(GlobalAveragePooling2D(input_shape=train_inception_resnet_v2.shape[1:]))\n",
    "# my_model.add(Dropout(0.2))\n",
    "# my_model.add(Dense(1000, activation='relu'))\n",
    "# my_model.add(BatchNormalization())\n",
    "# my_model.add(Dropout(0.2))\n",
    "# my_model.add(Dense(500, activation='relu'))\n",
    "# my_model.add(BatchNormalization())\n",
    "my_model.add(Dropout(0.3))\n",
    "my_model.add(Dense(133, activation='softmax'))\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define optimizer, loss function and metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr=0.002)\n",
    "my_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6712 samples, validate on 867 samples\n",
      "Epoch 1/10\n",
      "6688/6712 [============================>.] - ETA: 0s - loss: 1.3593 - acc: 0.6829\n",
      "Epoch 00001: val_loss improved from inf to 0.70290, saving model to saved_models/weights.best.inception_resnet_v2_transfer.hdf5\n",
      "6712/6712 [==============================] - 8s 1ms/step - loss: 1.3564 - acc: 0.6831 - val_loss: 0.7029 - val_acc: 0.7993\n",
      "Epoch 2/10\n",
      "6592/6712 [============================>.] - ETA: 0s - loss: 0.6935 - acc: 0.8049\n",
      "Epoch 00002: val_loss improved from 0.70290 to 0.63681, saving model to saved_models/weights.best.inception_resnet_v2_transfer.hdf5\n",
      "6712/6712 [==============================] - 3s 400us/step - loss: 0.6945 - acc: 0.8047 - val_loss: 0.6368 - val_acc: 0.8201\n",
      "Epoch 3/10\n",
      "6624/6712 [============================>.] - ETA: 0s - loss: 0.5709 - acc: 0.8344\n",
      "Epoch 00003: val_loss did not improve\n",
      "6712/6712 [==============================] - 2s 334us/step - loss: 0.5713 - acc: 0.8340 - val_loss: 0.6967 - val_acc: 0.8155\n",
      "Epoch 4/10\n",
      "6592/6712 [============================>.] - ETA: 0s - loss: 0.5147 - acc: 0.8477\n",
      "Epoch 00004: val_loss did not improve\n",
      "6712/6712 [==============================] - 2s 321us/step - loss: 0.5140 - acc: 0.8480 - val_loss: 0.7396 - val_acc: 0.8131\n",
      "Epoch 5/10\n",
      "6688/6712 [============================>.] - ETA: 0s - loss: 0.4421 - acc: 0.8683\n",
      "Epoch 00005: val_loss did not improve\n",
      "6712/6712 [==============================] - 3s 394us/step - loss: 0.4412 - acc: 0.8684 - val_loss: 0.6881 - val_acc: 0.8247\n",
      "Epoch 6/10\n",
      "6688/6712 [============================>.] - ETA: 0s - loss: 0.3863 - acc: 0.8804\n",
      "Epoch 00006: val_loss did not improve\n",
      "6712/6712 [==============================] - 3s 458us/step - loss: 0.3874 - acc: 0.8804 - val_loss: 0.7471 - val_acc: 0.8328\n",
      "Epoch 7/10\n",
      "6688/6712 [============================>.] - ETA: 0s - loss: 0.3504 - acc: 0.8886\n",
      "Epoch 00007: val_loss did not improve\n",
      "6712/6712 [==============================] - 3s 460us/step - loss: 0.3513 - acc: 0.8887 - val_loss: 0.7407 - val_acc: 0.8501\n",
      "Epoch 8/10\n",
      "6688/6712 [============================>.] - ETA: 0s - loss: 0.3374 - acc: 0.8910\n",
      "Epoch 00008: val_loss did not improve\n",
      "6712/6712 [==============================] - 3s 484us/step - loss: 0.3374 - acc: 0.8911 - val_loss: 0.7563 - val_acc: 0.8270\n",
      "Epoch 9/10\n",
      "6560/6712 [============================>.] - ETA: 0s - loss: 0.2960 - acc: 0.9014\n",
      "Epoch 00009: val_loss did not improve\n",
      "6712/6712 [==============================] - 2s 332us/step - loss: 0.2975 - acc: 0.9015 - val_loss: 0.7933 - val_acc: 0.8328\n",
      "Epoch 10/10\n",
      "6624/6712 [============================>.] - ETA: 0s - loss: 0.2667 - acc: 0.9135\n",
      "Epoch 00010: val_loss did not improve\n",
      "6712/6712 [==============================] - 2s 331us/step - loss: 0.2669 - acc: 0.9137 - val_loss: 0.7554 - val_acc: 0.8466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x185155e1d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.inception_resnet_v2_transfer.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "my_model.fit(train_inception_resnet_v2, labels_train_inception_resnet_v2, \n",
    "          validation_data=(valid_inception_resnet_v2, labels_valid_inception_resnet_v2),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best weights for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model.load_weights('saved_models/weights.best.inception_resnet_v2_transfer.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy over test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 80.7604%\n"
     ]
    }
   ],
   "source": [
    "# Expanding dimensions for the input features, adding 1 for the num of samples. \n",
    "# So it matches with the expected input from Keras\n",
    "# Using argmax to retrieve the index of the dog breed with maximum probability.\n",
    "inception_resnet_v2_predictions = [np.argmax(my_model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_inception_resnet_v2]\n",
    "\n",
    "# report test accuracy\n",
    "# Checking indexes from predictions and test labels.\n",
    "test_accuracy = 100*np.sum(np.array(inception_resnet_v2_predictions)==np.argmax(labels_test_inception_resnet_v2, axis=1))/len(labels_test_inception_resnet_v2)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
